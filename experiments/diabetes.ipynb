{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import wandb\n",
    "from .test_utils import (\n",
    "    test_skimmed_mclatte,\n",
    "    test_semi_skimmed_mclatte,\n",
    "    test_mclatte,\n",
    "    test_rnn,\n",
    "    test_losses,\n",
    ")\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(509)\n",
    "np.random.seed(509)\n",
    "torch.manual_seed(509)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SUBJECTS = 70\n",
    "M = 5\n",
    "H = 5\n",
    "R = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CODES = {\n",
    "    33: \"reg_insulin\",  # treatment\n",
    "    34: \"nph_insulin\",  # treatment\n",
    "    35: \"ult_insulin\",  # treatment\n",
    "    48: \"unspecified_bg\",  # outcome\n",
    "    57: \"unspecified_bg\",  # outcome\n",
    "    58: \"pre_breakfast_bg\",  # outcome\n",
    "    59: \"post_breakfast_bg\",  # outcome\n",
    "    60: \"pre_lunch_bg\",  # outcome\n",
    "    61: \"post_lunch_bg\",  # outcome\n",
    "    62: \"pre_supper_bg\",  # outcome\n",
    "    63: \"post_supper_bg\",  # outcome\n",
    "    64: \"pre_snack_bg\",  # outcome\n",
    "    65: \"hypo_symptoms\",  # covariate\n",
    "    66: \"typical_meal\",  # covariate\n",
    "    67: \"more_meal\",  # covariate\n",
    "    68: \"less_meal\",  # covariate\n",
    "    69: \"typical_exercise\",  # covariate\n",
    "    70: \"more_exercise\",  # covariate\n",
    "    71: \"less_exercise\",  # covariate\n",
    "    72: \"unspecified_event\",  # covariate\n",
    "}\n",
    "TREATMENT_COLS = [\"reg_insulin\", \"nph_insulin\", \"ult_insulin\"]\n",
    "OUTCOME_COLS = [\n",
    "    \"unspecified_bg\",\n",
    "    \"pre_breakfast_bg\",\n",
    "    \"post_breakfast_bg\",\n",
    "    \"pre_lunch_bg\",\n",
    "    \"post_lunch_bg\",\n",
    "    \"pre_supper_bg\",\n",
    "    \"post_supper_bg\",\n",
    "    \"pre_snack_bg\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def float_or_na(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except Exception as e:\n",
    "        if v == \"0Hi\":\n",
    "            return 1\n",
    "        if v == \"0Lo\":\n",
    "            return -1\n",
    "        print(e)\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(values):\n",
    "    valid_values = values[pd.notna(values)]\n",
    "    if valid_values.shape[0] == 0:\n",
    "        return np.nan\n",
    "    return np.median(valid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_date(v):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(v, \"%m-%d-%Y\")\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {v}\")\n",
    "    try:\n",
    "        v = v[:4] + \"0\" + v[5:]  # handle date mis-input (e.g. 6-31)\n",
    "        return datetime.datetime.strptime(v, \"%m-%d-%Y\")\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {v}\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_time(v):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(v, \"%H:%M\").time()\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {v}\")\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_to_combine(date, time):\n",
    "    try:\n",
    "        return datetime.datetime.combine(date, time)\n",
    "    except Exception as e:\n",
    "        print(f\"{e}: {date} {time}\")\n",
    "    if isinstance(date, datetime.datetime):\n",
    "        return date\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_i(subject_idx):\n",
    "    raw_df = pd.read_csv(\n",
    "        os.path.join(os.getcwd(), f\"data/diabetes/data-{subject_idx:02d}\"),\n",
    "        sep=\"\\t\",\n",
    "        names=[\"date\", \"time\", \"code\", \"value\"],\n",
    "    )\n",
    "    raw_df[\"date\"] = raw_df[\"date\"].apply(try_to_date)\n",
    "    raw_df[\"time\"] = raw_df[\"time\"].apply(try_to_time)\n",
    "    raw_df[\"datetime\"] = raw_df.apply(\n",
    "        lambda row: try_to_combine(row[\"date\"], row[\"time\"]), axis=1\n",
    "    )\n",
    "    raw_df.drop(columns=[\"date\", \"time\"], inplace=True)\n",
    "    raw_df.sort_values(by=[\"datetime\"], inplace=True)\n",
    "\n",
    "    all_datetimes = raw_df.datetime.values\n",
    "    converted_df = pd.DataFrame(\n",
    "        index=range(len(set(all_datetimes))), columns=list(DATA_CODES.values())\n",
    "    )\n",
    "\n",
    "    begin_idx = 0\n",
    "    converted_idx = 0\n",
    "    while begin_idx < raw_df.shape[0]:\n",
    "        while begin_idx < raw_df.shape[0] and np.isnan(all_datetimes[begin_idx]):\n",
    "            begin_idx += 1\n",
    "\n",
    "        end_idx = begin_idx\n",
    "        while (\n",
    "            end_idx < raw_df.shape[0]\n",
    "            and all_datetimes[end_idx] == all_datetimes[begin_idx]\n",
    "        ):\n",
    "            if raw_df.iloc[end_idx][\"code\"] in DATA_CODES:\n",
    "                col_name = DATA_CODES[raw_df.iloc[end_idx][\"code\"]]\n",
    "                converted_df.iloc[converted_idx][col_name] = float_or_na(\n",
    "                    raw_df.iloc[end_idx][\"value\"]\n",
    "                )\n",
    "            end_idx += 1\n",
    "        begin_idx = end_idx\n",
    "        converted_idx += 1\n",
    "\n",
    "    outcomes = converted_df.apply(lambda row: combine(row[OUTCOME_COLS]), axis=1)\n",
    "    treatment = converted_df[TREATMENT_COLS].apply(lambda col: combine(col), axis=0)\n",
    "    converted_df = converted_df[TREATMENT_COLS + OUTCOME_COLS]\n",
    "\n",
    "    mask_df = ~converted_df.isna()\n",
    "    converted_df[pd.isna(converted_df)] = 0\n",
    "    treatment[pd.isna(treatment)] = 0\n",
    "    return (\n",
    "        converted_df.to_numpy(),\n",
    "        mask_df.to_numpy(),\n",
    "        outcomes[pd.notna(outcomes)].to_numpy(),\n",
    "        treatment.to_numpy(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # Initialisation\n",
    "    X = []\n",
    "    M_ = []\n",
    "    Y_pre = []\n",
    "    Y_post = []\n",
    "    A = []\n",
    "\n",
    "    # Reading\n",
    "    for subject_idx in range(1, N_SUBJECTS + 1):\n",
    "        X_i, M_i, Y_i, A_i = load_subject_i(subject_idx)\n",
    "\n",
    "        if M * R > M_i.shape[0]:\n",
    "            M_.append(\n",
    "                np.concatenate((np.zeros((M * R - M_i.shape[0], M_i.shape[1])), M_i))\n",
    "            )\n",
    "        else:\n",
    "            M_.append(M_i[-M * R :])\n",
    "\n",
    "        if H + M > Y_i.shape[0]:\n",
    "            Y_pre.append(np.concatenate((np.zeros(H + M - Y_i.shape[0]), Y_i[:-H])))\n",
    "        else:\n",
    "            Y_pre.append(Y_i[-(H + M) : -H])\n",
    "\n",
    "        Y_post.append(Y_i[-H:])\n",
    "        A.append(A_i)\n",
    "        X_i = X_i[:-H]\n",
    "        if M * R > X_i.shape[0]:\n",
    "            X.append(\n",
    "                np.concatenate((np.zeros((M * R - X_i.shape[0], X_i.shape[1])), X_i))\n",
    "            )\n",
    "        else:\n",
    "            X.append(X_i[-M * R :])\n",
    "\n",
    "    # Aggregation\n",
    "    X = np.stack(X)\n",
    "    M_ = np.stack(M_)\n",
    "    Y_pre = np.array(Y_pre)\n",
    "    Y_post = np.array(Y_post)\n",
    "    A = np.array(A)\n",
    "    T = np.transpose(\n",
    "        np.tile(np.arange(-M * R, 0), (N_SUBJECTS, X.shape[2], 1)), (0, 2, 1)\n",
    "    )\n",
    "\n",
    "    # Scaling\n",
    "    X_to_scale = X.reshape((-1, X.shape[2]))  # (N, T, D) -> (N * T, D)\n",
    "    X_scaled = scale(X_to_scale, axis=0)\n",
    "    X = X_scaled.reshape(X.shape)\n",
    "\n",
    "    Y = np.concatenate((Y_pre, Y_post), axis=1)\n",
    "    Y_to_scale = Y.reshape((-1, 1))  # (N, M) + (N, H) -> (N * T, 1)\n",
    "    Y_scaled = scale(Y_to_scale, axis=0)\n",
    "    Y = Y_scaled.reshape(Y.shape)\n",
    "    Y_pre, Y_post = Y[:, :-H], Y[:, -H:]\n",
    "\n",
    "    A = scale(A, axis=0)  # [N, K]\n",
    "\n",
    "    return X, M_, Y_pre, Y_post, A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_write_data():\n",
    "    X, M_, Y_pre, Y_post, A, T = load_data()\n",
    "    joblib.dump(\n",
    "        (X, M_, Y_pre, Y_post, A, T),\n",
    "        os.path.join(os.getcwd(), \"data/diabetes/processed.joblib\"),\n",
    "    )\n",
    "\n",
    "    N = N_SUBJECTS\n",
    "    D = X.shape[2]\n",
    "    K = A.shape[1]\n",
    "    C = 4\n",
    "    joblib.dump(\n",
    "        (N, M, H, R, D, K, C, X, M_, Y_pre, Y_post, A, T),\n",
    "        os.path.join(os.getcwd(), f\"data/diabetes/hp_search.joblib\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(return_raw=True):\n",
    "    N_train = round(N_SUBJECTS * 0.8)\n",
    "    N_test = round(N_SUBJECTS * 0.2)\n",
    "    X, M_, Y_pre, Y_post, A, T = joblib.load(\n",
    "        os.path.join(os.getcwd(), \"data/diabetes/processed.joblib\")\n",
    "    )\n",
    "    X_train, X_test = X[:N_train], X[N_train:]\n",
    "    M_train, M_test = M_[:N_train], M_[N_train:]\n",
    "    Y_pre_train, Y_pre_test = Y_pre[:N_train], Y_pre[N_train:]\n",
    "    Y_post_train, Y_post_test = Y_post[:N_train], Y_post[N_train:]\n",
    "    A_train, A_test = A[:N_train], A[N_train:]\n",
    "    T_train, T_test = T[:N_train], T[N_train:]\n",
    "    all_data = (\n",
    "        N_SUBJECTS,\n",
    "        N_train,\n",
    "        N_test,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        M_train,\n",
    "        M_test,\n",
    "        Y_pre_train,\n",
    "        Y_pre_test,\n",
    "        Y_post_train,\n",
    "        Y_post_test,\n",
    "        A_train,\n",
    "        A_test,\n",
    "        T_train,\n",
    "        T_test,\n",
    "    )\n",
    "    if return_raw:\n",
    "        return all_data\n",
    "\n",
    "    train_data = dict(\n",
    "        n=N_train,\n",
    "        x=X_train,\n",
    "        m=M_train,\n",
    "        y_pre=Y_pre_train,\n",
    "        y_post=Y_post_train,\n",
    "        a=A_train,\n",
    "        t=T_train,\n",
    "    )\n",
    "    test_data = dict(\n",
    "        n=N_test,\n",
    "        x=X_test,\n",
    "        m=M_test,\n",
    "        y_pre=Y_pre_test,\n",
    "        y_post=Y_post_test,\n",
    "        a=A_test,\n",
    "        t=T_test,\n",
    "    )\n",
    "    return N_SUBJECTS, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, M, H, R, D, K, C, X, M_, Y_pre, Y_post, A, T = joblib.load(\n",
    "    os.path.join(os.getcwd(), f\"data/diabetes/hp_search.joblib\")\n",
    ")\n",
    "constants = dict(m=M, h=H, r=R, d=D, k=K, c=C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"mclatte-test\", entity=\"jasonyz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McLatte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/mclatte_hp.csv')).sort_values(by='valid_loss').iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclatte_config = {\n",
    "    \"encoder_class\": \"lstm\",\n",
    "    \"decoder_class\": \"lstm\",\n",
    "    \"hidden_dim\": 8,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.021089,\n",
    "    \"gamma\": 0.541449,\n",
    "    \"lambda_r\": 0.814086,\n",
    "    \"lambda_d\": 0.185784,\n",
    "    \"lambda_p\": 0.081336,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi-Skimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/semi_skimmed_mclatte_hp.csv')).sort_values(by='valid_loss').iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_skimmed_mclatte_config = {\n",
    "    \"encoder_class\": \"lstm\",\n",
    "    \"decoder_class\": \"lstm\",\n",
    "    \"hidden_dim\": 4,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.006606,\n",
    "    \"gamma\": 0.860694,\n",
    "    \"lambda_r\": 79.016676,\n",
    "    \"lambda_d\": 1.2907,\n",
    "    \"lambda_p\": 11.112241,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/skimmed_mclatte_hp.csv')).sort_values(by='valid_loss').iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skimmed_mclatte_config = {\n",
    "    \"encoder_class\": \"lstm\",\n",
    "    \"decoder_class\": \"lstm\",\n",
    "    \"hidden_dim\": 16,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.000928,\n",
    "    \"gamma\": 0.728492,\n",
    "    \"lambda_r\": 1.100493,\n",
    "    \"lambda_p\": 2.108935,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/baseline_rnn_hp.csv')).sort_values(by='valid_loss').iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_config = {\n",
    "    \"rnn_class\": \"gru\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"seq_len\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.006321,\n",
    "    \"gamma\": 0.543008,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SyncTwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/synctwin_hp.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "synctwin_config = {\n",
    "    \"hidden_dim\": 128,\n",
    "    \"reg_B\": 0.522652,\n",
    "    \"lam_express\": 0.163847,\n",
    "    \"lam_recon\": 0.39882,\n",
    "    \"lam_prognostic\": 0.837303,\n",
    "    \"tau\": 0.813696,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.001476,\n",
    "    \"gamma\": 0.912894,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    mclatte_losses = []\n",
    "    semi_skimmed_mclatte_losses = []\n",
    "    skimmed_mclatte_losses = []\n",
    "    rnn_losses = []\n",
    "    for i in range(1, N_TEST + 1):\n",
    "        (\n",
    "            _,\n",
    "            train_data,\n",
    "            test_data,\n",
    "        ) = generate_data(return_raw=False)\n",
    "\n",
    "        skimmed_mclatte_losses.append(\n",
    "            test_skimmed_mclatte(\n",
    "                skimmed_mclatte_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "        semi_skimmed_mclatte_losses.append(\n",
    "            test_semi_skimmed_mclatte(\n",
    "                semi_skimmed_mclatte_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "        mclatte_losses.append(\n",
    "            test_mclatte(\n",
    "                mclatte_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        rnn_losses.append(\n",
    "            test_rnn(\n",
    "                rnn_config,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        joblib.dump(\n",
    "            (\n",
    "                mclatte_losses,\n",
    "                semi_skimmed_mclatte_losses,\n",
    "                skimmed_mclatte_losses,\n",
    "                rnn_losses,\n",
    "            ),\n",
    "            f\"results/test/diabetes.joblib\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check finished runs results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_losses():\n",
    "    all_losses = joblib.load(f\"results/test/diabetes.joblib\")\n",
    "    for losses in all_losses:\n",
    "        print(f\"{np.mean(losses):.3f} ({np.std(losses):.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_NAMES = [\"McLatte\", \"Semi-Skimmed McLatte\", \"Skimmed McLatte\", \"RNN\", \"SyncTwin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = joblib.load(f\"results/test/diabetes.joblib\")\n",
    "test_losses(losses, LOSS_NAMES)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852d66bd2a456ad8c66b277a4fc8ac1a7bcd6ab870e3be824a8a6385faf13d3b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv.mclatte': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

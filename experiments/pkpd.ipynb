{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from .plot_utils import plot_config_results\n",
    "from .test_utils import (\n",
    "    test_skimmed_mclatte,\n",
    "    test_semi_skimmed_mclatte,\n",
    "    test_mclatte,\n",
    "    test_rnn,\n",
    "    test_synctwin,\n",
    ")\n",
    "from mclatte.synctwin import io_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants used for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_id = \"0.25_200\"\n",
    "seed = 509\n",
    "model_id = \"\"\n",
    "M = 5\n",
    "H = 5\n",
    "R = 5\n",
    "D = 3\n",
    "K = 1\n",
    "C = 3\n",
    "constants = dict(m=M, h=H, r=R, d=D, k=K, c=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(p_0, N, return_raw=True):\n",
    "    base_path_data = f\"data/pkpd/{p_0}_{N}-seed-{seed}\"\n",
    "    data_path = base_path_data + \"/{}-{}.{}\"\n",
    "\n",
    "    # loading config and data\n",
    "    io_utils.load_config(data_path, \"train\")\n",
    "    x_full, t_full, mask_full, _, y_full, _, _, _, _, _ = io_utils.load_tensor(\n",
    "        data_path, \"train\", device=\"cpu\"\n",
    "    )\n",
    "    (\n",
    "        x_full_val,\n",
    "        t_full_val,\n",
    "        mask_full_val,\n",
    "        _,\n",
    "        y_full_val,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "    ) = io_utils.load_tensor(data_path, \"val\", device=\"cpu\")\n",
    "\n",
    "    x = np.concatenate((x_full.cpu().numpy(), x_full_val.cpu().numpy()), axis=1)\n",
    "    t = np.concatenate((t_full.cpu().numpy(), t_full_val.cpu().numpy()), axis=1)\n",
    "    mask = np.concatenate(\n",
    "        (mask_full.cpu().numpy(), mask_full_val.cpu().numpy()), axis=1\n",
    "    )\n",
    "    y = np.concatenate(\n",
    "        (y_full.cpu().numpy(), y_full_val.cpu().numpy()), axis=1\n",
    "    ).squeeze()\n",
    "\n",
    "    X = x.transpose((1, 0, 2))\n",
    "    N = X.shape[0]\n",
    "    rand_index = np.random.permutation(N)\n",
    "    X = X[rand_index]\n",
    "    M_ = mask.transpose((1, 0, 2))[rand_index]\n",
    "    Y_pre = y.T[rand_index]\n",
    "    Y_post = y.T[rand_index]\n",
    "    A = np.concatenate(\n",
    "        (\n",
    "            np.zeros((N // 4, 1)),\n",
    "            np.ones((N // 4, 1)),\n",
    "            np.zeros((N // 4, 1)),\n",
    "            np.ones((N // 4, 1)),\n",
    "        ),\n",
    "        axis=0,\n",
    "    )[rand_index]\n",
    "    T = t.transpose((1, 0, 2))[rand_index]\n",
    "\n",
    "    N_train = round(N * 0.8)\n",
    "    N_test = round(N * 0.2)\n",
    "    X_train, X_test = X[:N_train], X[N_train:]\n",
    "    M_train, M_test = M_[:N_train], M_[N_train:]\n",
    "    Y_pre_train, Y_pre_test = Y_pre[:N_train], Y_pre[N_train:]\n",
    "    Y_post_train, Y_post_test = Y_post[:N_train], Y_post[N_train:]\n",
    "    A_train, A_test = A[:N_train], A[N_train:]\n",
    "    T_train, T_test = T[:N_train], T[N_train:]\n",
    "\n",
    "    all_data = (\n",
    "        (\n",
    "            N_train,\n",
    "            M,\n",
    "            H,\n",
    "            R,\n",
    "            D,\n",
    "            K,\n",
    "            C,\n",
    "            X_train,\n",
    "            M_train,\n",
    "            Y_pre_train,\n",
    "            Y_post_train,\n",
    "            A_train,\n",
    "            T_train,\n",
    "        ),\n",
    "        (\n",
    "            N_test,\n",
    "            M,\n",
    "            H,\n",
    "            R,\n",
    "            D,\n",
    "            K,\n",
    "            C,\n",
    "            X_test,\n",
    "            M_test,\n",
    "            Y_pre_test,\n",
    "            Y_post_test,\n",
    "            A_test,\n",
    "            T_test,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    if return_raw:\n",
    "        return all_data\n",
    "\n",
    "    train_data = dict(\n",
    "        n=N_train,\n",
    "        x=X_train,\n",
    "        m=M_train,\n",
    "        y_pre=Y_pre_train,\n",
    "        y_post=Y_post_train,\n",
    "        a=A_train,\n",
    "        t=T_train,\n",
    "    )\n",
    "    test_data = dict(\n",
    "        n=N_test,\n",
    "        x=X_test,\n",
    "        m=M_test,\n",
    "        y_pre=Y_pre_test,\n",
    "        y_post=Y_post_test,\n",
    "        a=A_test,\n",
    "        t=T_test,\n",
    "    )\n",
    "    return N, train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McLatte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results_pkpd/mclatte_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "mclatte_config = {\n",
    "    \"encoder_class\": \"lstm\",\n",
    "    \"decoder_class\": \"lstm\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.001944,\n",
    "    \"gamma\": 0.957115,\n",
    "    \"lambda_r\": 0.311437,\n",
    "    \"lambda_d\": 0.118073,\n",
    "    \"lambda_p\": 0.49999,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi-Skimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results_pkpd/semi_skimmed_mclatte_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "semi_skimmed_mclatte_config = {\n",
    "    \"encoder_class\": \"lstm\",\n",
    "    \"decoder_class\": \"lstm\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.001944,\n",
    "    \"gamma\": 0.957115,\n",
    "    \"lambda_r\": 0.311437,\n",
    "    \"lambda_d\": 0.118073,\n",
    "    \"lambda_p\": 0.49999,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results_pkpd/skimmed_mclatte_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "skimmed_mclatte_config = {\n",
    "    \"encoder_class\": \"lstm\",\n",
    "    \"decoder_class\": \"lstm\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.021114,\n",
    "    \"gamma\": 0.980614,\n",
    "    \"lambda_r\": 0.093878,\n",
    "    \"lambda_p\": 0.485204,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/baseline_rnn_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "rnn_config = {\n",
    "    \"rnn_class\": \"gru\",\n",
    "    \"hidden_dim\": 64,\n",
    "    \"seq_len\": 2,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.025182,\n",
    "    \"gamma\": 0.543008,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SyncTwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/synctwin_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "synctwin_config = {\n",
    "    \"hidden_dim\": 128,\n",
    "    \"reg_B\": 0.778155,\n",
    "    \"lam_express\": 0.658256,\n",
    "    \"lam_recon\": 0.086627,\n",
    "    \"lam_prognostic\": 0.631468,\n",
    "    \"tau\": 0.911613,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.003222,\n",
    "    \"gamma\": 0.572529,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CONFIGS = [\n",
    "    [\"0.1\", 200],\n",
    "    [\"0.25\", 200],\n",
    "    [\"0.5\", 200],\n",
    "    [\"0.1\", 1000],\n",
    "    [\"0.25\", 1000],\n",
    "    [\"0.5\", 1000],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_idx in range(0):\n",
    "    config = TEST_CONFIGS[config_idx]\n",
    "    mclatte_losses = []\n",
    "    semi_skimmed_mclatte_losses = []\n",
    "    skimmed_mclatte_losses = []\n",
    "    rnn_losses = []\n",
    "    synctwin_losses = []\n",
    "    for i in range(N_TEST * config_idx + 1, N_TEST * (1 + config_idx) + 1):\n",
    "        _, train_data, test_data = generate_data(config[0], config[1], return_raw=False)\n",
    "\n",
    "        skimmed_mclatte_losses.append(\n",
    "            test_skimmed_mclatte(\n",
    "                skimmed_mclatte_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "        semi_skimmed_mclatte_losses.append(\n",
    "            test_semi_skimmed_mclatte(\n",
    "                semi_skimmed_mclatte_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "        mclatte_losses.append(\n",
    "            test_mclatte(\n",
    "                mclatte_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        rnn_losses.append(\n",
    "            test_rnn(\n",
    "                rnn_config,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        synctwin_losses.append(\n",
    "            test_synctwin(\n",
    "                synctwin_config,\n",
    "                constants,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                run_idx=i,\n",
    "            )\n",
    "        )\n",
    "        joblib.dump(\n",
    "            (\n",
    "                config,\n",
    "                mclatte_losses,\n",
    "                semi_skimmed_mclatte_losses,\n",
    "                skimmed_mclatte_losses,\n",
    "                rnn_losses,\n",
    "                synctwin_losses,\n",
    "            ),\n",
    "            f\"results/test/config_{config_idx}_pkpd.joblib\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_NAMES = [\"McLatte\", \"Semi-Skimmed McLatte\", \"Skimmed McLatte\", \"RNN\", \"SyncTwin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McLatte & .5000 & .3377 & .0003 & .0001 & .0000 \\\\\n",
      "Semi-Skimmed McLatte & .6623 & .5000 & .0003 & .0001 & .0000 \\\\\n",
      "Skimmed McLatte & .9997 & .9997 & .5000 & .0019 & .0000 \\\\\n",
      "RNN & .9999 & .9999 & .9981 & .5000 & .1806 \\\\\n",
      "SyncTwin & .0000 & .0000 & .0000 & .8194 & .5000 \\\\\n"
     ]
    }
   ],
   "source": [
    "all_losses = [[] for _ in range(len(LOSS_NAMES))]\n",
    "for config_id in range(len(TEST_CONFIGS)):\n",
    "    _, *losses = joblib.load(f\"results_pkpd/maes/config_{config_id}_pkpd.joblib\")\n",
    "    # print(test_losses(losses))\n",
    "    for i in range(len(LOSS_NAMES)):\n",
    "        all_losses[i] += losses[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for config_id in range(len(TEST_CONFIGS)):\n",
    "    plot_config_results(\"pkpd\", TEST_CONFIGS, generate_data, config_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852d66bd2a456ad8c66b277a4fc8ac1a7bcd6ab870e3be824a8a6385faf13d3b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv.mclatte': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

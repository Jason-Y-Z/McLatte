{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from mclatte.model import train_mclatte, train_semi_skimmed_mclatte, train_skimmed_mclatte\n",
    "from rnn.model import train_baseline_rnn\n",
    "from synctwin import io_utils\n",
    "from synctwin.model import train_synctwin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants used for generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_id = '0.25_200'\n",
    "seed = 509\n",
    "model_id = \"\"\n",
    "M = 5\n",
    "H = 5\n",
    "R = 5 \n",
    "D = 3 \n",
    "K = 1 \n",
    "C = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(p_0, N):\n",
    "    base_path_data = f\"data/pkpd/{p_0}_{N}-seed-{seed}\"\n",
    "    data_path = base_path_data + \"/{}-{}.{}\"\n",
    "\n",
    "    # loading config and data\n",
    "    io_utils.load_config(\n",
    "        data_path, \"train\"\n",
    "    )\n",
    "    x_full, t_full, mask_full, _, y_full, _, _, _, _, _ = io_utils.load_tensor(data_path, \"train\", device='cpu')\n",
    "    x_full_val, t_full_val, mask_full_val, _, y_full_val, _, _, _, _, _ = io_utils.load_tensor(data_path, \"val\", device='cpu')\n",
    "\n",
    "    x = np.concatenate((x_full.cpu().numpy(), x_full_val.cpu().numpy()), axis=1)\n",
    "    t = np.concatenate((t_full.cpu().numpy(), t_full_val.cpu().numpy()), axis=1)\n",
    "    mask = np.concatenate((mask_full.cpu().numpy(), mask_full_val.cpu().numpy()), axis=1)\n",
    "    y = np.concatenate((y_full.cpu().numpy(), y_full_val.cpu().numpy()), axis=1).squeeze()\n",
    "\n",
    "    X = x.transpose((1, 0, 2))\n",
    "    N = X.shape[0]\n",
    "    print(N)\n",
    "    rand_index = np.random.permutation(N)\n",
    "    X = X[rand_index]\n",
    "    M_ = mask.transpose((1, 0, 2))[rand_index]\n",
    "    Y_pre = y.T[rand_index]\n",
    "    Y_post = y.T[rand_index]\n",
    "    A = np.concatenate((np.zeros((N // 4, 1)), np.ones((N // 4, 1)), np.zeros((N // 4, 1)), np.ones((N // 4, 1))), axis=0)[rand_index]\n",
    "    T = t.transpose((1, 0, 2))[rand_index]\n",
    "\n",
    "    N_train = round(N * 0.8)\n",
    "    N_test = round(N * 0.2)\n",
    "    X_train, X_test = X[:N_train], X[N_train:]\n",
    "    M_train, M_test = M_[:N_train], M_[N_train:]\n",
    "    Y_pre_train, Y_pre_test = Y_pre[:N_train], Y_pre[N_train:]\n",
    "    Y_post_train, Y_post_test = Y_post[:N_train], Y_post[N_train:]\n",
    "    A_train, A_test = A[:N_train], A[N_train:]\n",
    "    T_train, T_test = T[:N_train], T[N_train:]\n",
    "\n",
    "    return (\n",
    "        (N_train, M, H, R, D, K, C, X_train, M_train, Y_pre_train, Y_post_train, A_train, T_train),\n",
    "        (N_test, M, H, R, D, K, C, X_test, M_test, Y_pre_test, Y_post_test, A_test, T_test),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump((N_train, M, H, R, D, K, C, X_train, M_train, Y_pre_train, Y_post_train, A_train, T_train), f'data/pkpd/data_{sim_id}.joblib')\n",
    "# joblib.dump((N_test, M, H, R, D, K, C, X_test, M_test, Y_pre_test, Y_post_test, A_test, T_test), f'data/pkpd/test_data_{sim_id}.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_catcher(func):\n",
    "    def wrapper_na_catcher(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return np.nan\n",
    "    return wrapper_na_catcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### McLatte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results_pkpd/mclatte_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "mclatte_config = {\n",
    "    'encoder_class': 'lstm',\n",
    "    'decoder_class': 'lstm',\n",
    "    'hidden_dim': 64,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.001944,\n",
    "    'gamma': 0.957115,\n",
    "    'lambda_r': 0.311437,\n",
    "    'lambda_d': 0.118073,\n",
    "    'lambda_p': 0.49999,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mclatte(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    M_train, \n",
    "    M_test, \n",
    "    Y_pre_train, \n",
    "    Y_post_train, \n",
    "    Y_post_test, \n",
    "    A_train, \n",
    "    A_test, \n",
    "    T_train, \n",
    "    T_test,\n",
    "    run_idx=0,\n",
    "):\n",
    "    trained_mclatte = train_mclatte(\n",
    "        mclatte_config,\n",
    "        X_train,\n",
    "        M_train,\n",
    "        Y_pre_train,\n",
    "        Y_post_train,\n",
    "        A_train, \n",
    "        T_train,\n",
    "        R,\n",
    "        M,\n",
    "        H,\n",
    "        input_dim=D, \n",
    "        treatment_dim=K, \n",
    "        test_run=run_idx,\n",
    "    )\n",
    "\n",
    "    trained_mclatte.eval()\n",
    "    _, _, y_tilde = trained_mclatte(\n",
    "        torch.from_numpy(X_test).float(),\n",
    "        torch.from_numpy(A_test).float(),\n",
    "        torch.from_numpy(T_test).float(),\n",
    "        torch.from_numpy(M_test).float(),\n",
    "    )\n",
    "    \n",
    "    return torch.nn.functional.l1_loss(\n",
    "        y_tilde, \n",
    "        torch.from_numpy(Y_post_test).float()\n",
    "    ).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semi-Skimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results_pkpd/semi_skimmed_mclatte_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "semi_skimmed_mclatte_config = {\n",
    "    'encoder_class': 'lstm',\n",
    "    'decoder_class': 'lstm',\n",
    "    'hidden_dim': 64,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.001944,\n",
    "    'gamma': 0.957115,\n",
    "    'lambda_r': 0.311437,\n",
    "    'lambda_d': 0.118073,\n",
    "    'lambda_p': 0.49999,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_semi_skimmed_mclatte(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    M_train, \n",
    "    M_test, \n",
    "    Y_pre_train, \n",
    "    Y_post_train, \n",
    "    Y_post_test, \n",
    "    A_train, \n",
    "    A_test, \n",
    "    T_train, \n",
    "    T_test,\n",
    "    run_idx=0,\n",
    "):\n",
    "    trained_semi_skimmed_mclatte = train_semi_skimmed_mclatte(\n",
    "        semi_skimmed_mclatte_config,\n",
    "        X_train,\n",
    "        M_train,\n",
    "        Y_pre_train,\n",
    "        Y_post_train,\n",
    "        A_train, \n",
    "        T_train,\n",
    "        R,\n",
    "        M,\n",
    "        H,\n",
    "        input_dim=D, \n",
    "        treatment_dim=K, \n",
    "        test_run=run_idx,\n",
    "    )\n",
    "\n",
    "    trained_semi_skimmed_mclatte.eval()\n",
    "    _, _, y_tilde = trained_semi_skimmed_mclatte(\n",
    "        torch.from_numpy(X_test).float(),\n",
    "        torch.from_numpy(A_test).float(),\n",
    "        torch.from_numpy(T_test).float(),\n",
    "        torch.from_numpy(M_test).float(),\n",
    "    )\n",
    "    \n",
    "    return torch.nn.functional.l1_loss(\n",
    "        y_tilde, \n",
    "        torch.from_numpy(Y_post_test).float()\n",
    "    ).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results_pkpd/skimmed_mclatte_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "skimmed_mclatte_config = {\n",
    "    'encoder_class': 'lstm',\n",
    "    'decoder_class': 'lstm',\n",
    "    'hidden_dim': 64,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.021114,\n",
    "    'gamma': 0.980614,\n",
    "    'lambda_r': 0.093878,\n",
    "    'lambda_s': 0.485204,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_skimmed_mclatte(\n",
    "    X_train, \n",
    "    X_test, \n",
    "    M_train, \n",
    "    M_test, \n",
    "    Y_pre_train, \n",
    "    Y_post_train, \n",
    "    Y_post_test, \n",
    "    A_train, \n",
    "    A_test, \n",
    "    T_train, \n",
    "    T_test,\n",
    "    run_idx=0,\n",
    "):\n",
    "    trained_skimmed_mclatte = train_skimmed_mclatte(\n",
    "        skimmed_mclatte_config,\n",
    "        X_train,\n",
    "        M_train,\n",
    "        Y_pre_train,\n",
    "        Y_post_train,\n",
    "        A_train, \n",
    "        T_train,\n",
    "        R,\n",
    "        M,\n",
    "        H,\n",
    "        input_dim=D, \n",
    "        treatment_dim=K, \n",
    "        test_run=run_idx,\n",
    "    )\n",
    "\n",
    "    trained_skimmed_mclatte.eval()\n",
    "    _, y_tilde = trained_skimmed_mclatte(\n",
    "        torch.from_numpy(X_test).float(),\n",
    "        torch.from_numpy(A_test).float(),\n",
    "        torch.from_numpy(T_test).float(),\n",
    "        torch.from_numpy(M_test).float(),\n",
    "    )\n",
    "    \n",
    "    return torch.nn.functional.l1_loss(\n",
    "        y_tilde, \n",
    "        torch.from_numpy(Y_post_test).float()\n",
    "    ).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/baseline_rnn_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "rnn_config = {\n",
    "    'rnn_class': 'gru',\n",
    "    'hidden_dim': 64,\n",
    "    'seq_len': 2,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.025182,\n",
    "    'gamma': 0.543008,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_predict(trained_rnn, Y_pre, Y_post):\n",
    "    \"\"\"\n",
    "    Make predictions using results from previous time steps.\n",
    "    \"\"\"\n",
    "    Y = Y_pre\n",
    "    losses = 0.0\n",
    "    for i in range(Y_post.shape[1]):\n",
    "        Y_tilde = trained_rnn(\n",
    "            torch.from_numpy(Y).float().unsqueeze(2)\n",
    "        ).squeeze()\n",
    "\n",
    "        Y = np.concatenate((\n",
    "            Y[:, 1:], \n",
    "            Y_tilde.cpu().detach().numpy()[:, [-1]]\n",
    "        ), axis=1)\n",
    "        \n",
    "        losses += torch.nn.functional.l1_loss(\n",
    "            Y_tilde[:, -1], \n",
    "            torch.from_numpy(Y_post).float()[:, i]\n",
    "        ).item()\n",
    "    return losses / Y_post.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rnn(\n",
    "    Y_pre_train, \n",
    "    Y_pre_test, \n",
    "    Y_post_train, \n",
    "    Y_post_test, \n",
    "    run_idx=0,\n",
    "):\n",
    "    trained_rnn = train_baseline_rnn(\n",
    "        rnn_config,\n",
    "        Y=np.concatenate((Y_pre_train, Y_post_train), axis=1),\n",
    "        input_dim=1, \n",
    "        test_run=run_idx,\n",
    "    )\n",
    "\n",
    "    trained_rnn.eval()\n",
    "    return rnn_predict(trained_rnn, Y_pre_test, Y_post_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SyncTwin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.read_csv(os.path.join(os.getcwd(), 'results/synctwin_hp_pkpd.csv')).sort_values(by='valid_loss').iloc[0])\n",
    "synctwin_config = {\n",
    "    'hidden_dim': 128,\n",
    "    'reg_B': 0.778155,\n",
    "    'lam_express': 0.658256,\n",
    "    'lam_recon': 0.086627,\n",
    "    'lam_prognostic': 0.631468,\n",
    "    'tau': 0.911613,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.003222,\n",
    "    'gamma': 0.572529,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_synctwin(\n",
    "    N_train, \n",
    "    N_test, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    M_train, \n",
    "    M_test, \n",
    "    Y_post_train, \n",
    "    Y_post_test, \n",
    "    A_train, \n",
    "    A_test, \n",
    "    T_train, \n",
    "    T_test,\n",
    "    run_idx=0,\n",
    "):\n",
    "    Y_mask_train = np.all(A_train == 0, axis=1)\n",
    "    Y_mask_test = np.all(A_test == 0, axis=1)\n",
    "    Y_control_train = Y_post_train[Y_mask_train]\n",
    "\n",
    "    trained_synctwin = train_synctwin(\n",
    "        synctwin_config,\n",
    "        X=X_train,\n",
    "        M_=M_train,\n",
    "        T=T_train,\n",
    "        Y_batch=Y_post_train,\n",
    "        Y_control=Y_control_train,\n",
    "        Y_mask=Y_mask_train, \n",
    "        N=N_train,\n",
    "        D=D,\n",
    "        n_treated=N_train - Y_control_train.shape[0],\n",
    "        pre_trt_x_len=R * M,\n",
    "        test_run=run_idx,\n",
    "    ).cuda()\n",
    "\n",
    "    trained_synctwin.eval()\n",
    "    _, l1_loss = trained_synctwin(\n",
    "        torch.from_numpy(X_test).float().cuda(),\n",
    "        torch.from_numpy(T_test).float().cuda(),\n",
    "        torch.from_numpy(M_test).float().cuda(),\n",
    "        torch.arange(0, N_test).cuda(),\n",
    "        torch.from_numpy(Y_post_test).float().cuda(),\n",
    "        torch.from_numpy(Y_mask_test).float().cuda(),\n",
    "    )\n",
    "    return l1_loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TEST = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CONFIGS = [\n",
    "    [200, '0.1'],\n",
    "    [200, '0.25'],\n",
    "    [200, '0.5'],\n",
    "    [1000, '0.1'],\n",
    "    [1000, '0.25'],\n",
    "    [1000, '0.5'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_1_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session not detected. You should not be calling `report` outside `tune.run` or while using the class API. \n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/nj/375nskl94kg9r59g0kqr9cs80000gn/T/ipykernel_7861/3152192163.py\", line 13, in <module>\n",
      "    mclatte_losses.append(test_mclatte(\n",
      "  File \"/var/folders/nj/375nskl94kg9r59g0kqr9cs80000gn/T/ipykernel_7861/23854258.py\", line 4, in wrapper_na_catcher\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/var/folders/nj/375nskl94kg9r59g0kqr9cs80000gn/T/ipykernel_7861/1502680435.py\", line 16, in test_mclatte\n",
      "    trained_mclatte = train_mclatte(\n",
      "  File \"/Users/jasonyz/Documents/McLatte/mclatte/model.py\", line 418, in train_mclatte\n",
      "    return train_mcespresso(\n",
      "  File \"/Users/jasonyz/Documents/McLatte/mclatte/model.py\", line 270, in train_mcespresso\n",
      "    trainer.fit(pl_model, data_module)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
      "    self._run(model)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
      "    self._dispatch()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
      "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 112, in run\n",
      "    self.on_advance_end()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 177, in on_advance_end\n",
      "    self._run_validation()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 257, in _run_validation\n",
      "    self.val_loop.run()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
      "    output = self.on_run_end()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 142, in on_run_end\n",
      "    self.on_evaluation_end()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 205, in on_evaluation_end\n",
      "    self.trainer.call_hook(\"on_validation_end\", *args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1228, in call_hook\n",
      "    trainer_hook(*args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 229, in on_validation_end\n",
      "    callback.on_validation_end(self, self.lightning_module)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ray/tune/integration/pytorch_lightning.py\", line 118, in on_validation_end\n",
      "    self._handle(trainer, pl_module)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ray/tune/integration/pytorch_lightning.py\", line 202, in _handle\n",
      "    tune.report(**report_dict)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_1_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session not detected. You should not be calling `report` outside `tune.run` or while using the class API. \n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2914, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3185, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/nj/375nskl94kg9r59g0kqr9cs80000gn/T/ipykernel_7861/3152192163.py\", line 27, in <module>\n",
      "    semi_skimmed_mclatte_losses.append(test_semi_skimmed_mclatte(\n",
      "  File \"/var/folders/nj/375nskl94kg9r59g0kqr9cs80000gn/T/ipykernel_7861/23854258.py\", line 4, in wrapper_na_catcher\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/var/folders/nj/375nskl94kg9r59g0kqr9cs80000gn/T/ipykernel_7861/3123067373.py\", line 16, in test_semi_skimmed_mclatte\n",
      "    trained_semi_skimmed_mclatte = train_semi_skimmed_mclatte(\n",
      "  File \"/Users/jasonyz/Documents/McLatte/mclatte/model.py\", line 364, in train_semi_skimmed_mclatte\n",
      "    return train_mcespresso(\n",
      "  File \"/Users/jasonyz/Documents/McLatte/mclatte/model.py\", line 270, in train_mcespresso\n",
      "    trainer.fit(pl_model, data_module)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 552, in fit\n",
      "    self._run(model)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 922, in _run\n",
      "    self._dispatch()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 990, in _dispatch\n",
      "    self.accelerator.start_training(self)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 92, in start_training\n",
      "    self.training_type_plugin.start_training(trainer)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 161, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1000, in run_stage\n",
      "    return self._run_train()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1049, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 111, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py\", line 200, in advance\n",
      "    epoch_output = self.epoch_loop.run(train_dataloader)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 112, in run\n",
      "    self.on_advance_end()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 177, in on_advance_end\n",
      "    self._run_validation()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 257, in _run_validation\n",
      "    self.val_loop.run()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/base.py\", line 118, in run\n",
      "    output = self.on_run_end()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 142, in on_run_end\n",
      "    self.on_evaluation_end()\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 205, in on_evaluation_end\n",
      "    self.trainer.call_hook(\"on_validation_end\", *args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 1228, in call_hook\n",
      "    trainer_hook(*args, **kwargs)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/callback_hook.py\", line 229, in on_validation_end\n",
      "    callback.on_validation_end(self, self.lightning_module)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ray/tune/integration/pytorch_lightning.py\", line 118, in on_validation_end\n",
      "    self._handle(trainer, pl_module)\n",
      "  File \"/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/ray/tune/integration/pytorch_lightning.py\", line 202, in _handle\n",
      "    tune.report(**report_dict)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_2_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_2_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_3_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_3_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_4_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_4_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_5_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_5_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_6_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_6_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_7_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_7_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_8_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/semi_skimmed_mclatte_8_pkpd.ckpt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jasonyz/Documents/McLatte/.venv.mclatte/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "\n",
      "  | Name     | Type        | Params\n",
      "-----------------------------------------\n",
      "0 | _encoder | LstmEncoder | 22.0 K\n",
      "1 | _decoder | LstmDecoder | 33.5 K\n",
      "-----------------------------------------\n",
      "56.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "56.1 K    Total params\n",
      "0.224     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[Errno 2] No such file or directory: '/Users/jasonyz/Documents/McLatte/results/mclatte_9_pkpd.ckpt'\n"
     ]
    }
   ],
   "source": [
    "for config_idx in range(len(TEST_CONFIGS)):\n",
    "    config = TEST_CONFIGS[config_idx]\n",
    "    mclatte_losses = []\n",
    "    semi_skimmed_mclatte_losses = []\n",
    "    skimmed_mclatte_losses = []\n",
    "    rnn_losses = []\n",
    "    synctwin_losses = []\n",
    "    for i in range(N_TEST * config_idx + 1, N_TEST * (1 + config_idx) + 1):\n",
    "        (\n",
    "            (N_train, M, H, R, D, K, C, X_train, M_train, Y_pre_train, Y_post_train, A_train, T_train),\n",
    "            (N_test, M, H, R, D, K, C, X_test, M_test, Y_pre_test, Y_post_test, A_test, T_test),\n",
    "        ) = generate_data(config[1], config[0])\n",
    "\n",
    "        mclatte_losses.append(test_mclatte(\n",
    "            X_train, \n",
    "            X_test, \n",
    "            M_train, \n",
    "            M_test, \n",
    "            Y_pre_train, \n",
    "            Y_post_train, \n",
    "            Y_post_test, \n",
    "            A_train, \n",
    "            A_test, \n",
    "            T_train, \n",
    "            T_test,\n",
    "            run_idx=i,\n",
    "        ))\n",
    "        semi_skimmed_mclatte_losses.append(test_semi_skimmed_mclatte(\n",
    "            X_train, \n",
    "            X_test, \n",
    "            M_train, \n",
    "            M_test, \n",
    "            Y_pre_train, \n",
    "            Y_post_train, \n",
    "            Y_post_test, \n",
    "            A_train, \n",
    "            A_test, \n",
    "            T_train, \n",
    "            T_test,\n",
    "            run_idx=i,\n",
    "        ))\n",
    "        skimmed_mclatte_losses.append(test_skimmed_mclatte(\n",
    "            X_train, \n",
    "            X_test, \n",
    "            M_train, \n",
    "            M_test, \n",
    "            Y_pre_train, \n",
    "            Y_post_train, \n",
    "            Y_post_test, \n",
    "            A_train, \n",
    "            A_test, \n",
    "            T_train, \n",
    "            T_test,\n",
    "            run_idx=i,\n",
    "        ))\n",
    "\n",
    "        rnn_losses.append(test_rnn(\n",
    "            Y_pre_train,\n",
    "            Y_pre_test,\n",
    "            Y_post_train,\n",
    "            Y_post_test,\n",
    "            run_idx=i,\n",
    "        ))\n",
    "\n",
    "        synctwin_losses.append(test_synctwin(\n",
    "            N_train, \n",
    "            N_test, \n",
    "            X_train, \n",
    "            X_test, \n",
    "            M_train, \n",
    "            M_test, \n",
    "            Y_post_train, \n",
    "            Y_post_test, \n",
    "            A_train, \n",
    "            A_test, \n",
    "            T_train, \n",
    "            T_test,\n",
    "            run_idx=i,\n",
    "        ))\n",
    "        joblib.dump((\n",
    "            config, \n",
    "            mclatte_losses, \n",
    "            semi_skimmed_mclatte_losses, \n",
    "            skimmed_mclatte_losses, \n",
    "            rnn_losses, \n",
    "            synctwin_losses\n",
    "        ), f'results/test/config_{config_idx}_pkpd.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "852d66bd2a456ad8c66b277a4fc8ac1a7bcd6ab870e3be824a8a6385faf13d3b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('.venv.mclatte': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
